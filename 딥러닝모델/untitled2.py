# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jGVK1uYOaCtg-Yg14UNtS-LtNnfVi0lV
"""

from google.colab import drive
drive.mount('/content/gdrive/')

from keras.preprocessing import image
import matplotlib.pyplot as plt
import os, shutil

# 훈련, 검증, 테스트 분할을 위한 디렉터리
base_dir = '/content/gdrive/MyDrive/한이음자율형'
train_dir = os.path.join(base_dir, 'train')
os.mkdir(train_dir)
validation_dir = os.path.join(base_dir, 'validation')
os.mkdir(validation_dir)
test_dir = os.path.join(base_dir, 'test')
os.mkdir(test_dir)

# 훈련용 사진 디렉터리
train_f_dir = os.path.join(train_dir, 'train_F')
os.mkdir(train_f_dir)

# 훈련용 사진 디렉터리
train_b_dir = os.path.join(train_dir, 'train_B')
os.mkdir(train_b_dir)
######################################################################
# 검증용 사진 디렉터리
validation_f_dir = os.path.join(validation_dir, 'valid_F')
os.mkdir(validation_f_dir)

# 검증용 사진 디렉터리
validation_b_dir = os.path.join(validation_dir, 'valid_B')
os.mkdir(validation_b_dir)
######################################################################
# 테스트용 사진 디렉터리
test_f_dir = os.path.join(test_dir, 'test_F')
os.mkdir(test_f_dir)

# 테스트용 사진 디렉터리
test_b_dir = os.path.join(test_dir, 'test_B')
os.mkdir(test_b_dir)

original_f_dataset_dir = '/content/gdrive/MyDrive/한이음자율형/resize_front_150'
original_b_dataset_dir = '/content/gdrive/MyDrive/한이음자율형/resize_back_150'

fnames = ['1_{}.jpg'.format(i+1) for i in range(300)]
for fname in fnames:
    src = os.path.join(original_f_dataset_dir, fname)
    dst = os.path.join(train_f_dir, fname)
    shutil.copyfile(src, dst)


fnames = ['1_{}.jpg'.format(i+1) for i in range(300,450)]
for fname in fnames:
    src = os.path.join(original_f_dataset_dir, fname)
    dst = os.path.join(validation_f_dir, fname)
    shutil.copyfile(src, dst)
    

fnames = ['1_{}.jpg'.format(i+1) for i in range(450,500)]
for fname in fnames:
    src = os.path.join(original_f_dataset_dir, fname)
    dst = os.path.join(test_f_dir, fname)
    shutil.copyfile(src, dst)

fnames = ['0_{}.jpg'.format(i+1) for i in range(300)]
for fname in fnames:
    src = os.path.join(original_b_dataset_dir, fname)
    dst = os.path.join(train_b_dir, fname)
    shutil.copyfile(src, dst)


fnames = ['0_{}.jpg'.format(i+1) for i in range(300,450)]
for fname in fnames:
    src = os.path.join(original_b_dataset_dir, fname)
    dst = os.path.join(validation_b_dir, fname)
    shutil.copyfile(src, dst)
    

fnames = ['0_{}.jpg'.format(i+1) for i in range(450,500)]
for fname in fnames:
    src = os.path.join(original_b_dataset_dir, fname)
    dst = os.path.join(test_b_dir, fname)
    shutil.copyfile(src, dst)

from keras import layers
from keras import models

model = models.Sequential()
model.add(layers.Flatten(input_shape=(150, 150, 3)))
model.add(layers.Dense(128, activation = 'relu'))
model.add(layers.Dense(1, activation = 'sigmoid'))

model.summary()

from keras import optimizers

model.compile(loss = 'binary_crossentropy', optimizer=optimizers.RMSprop(learning_rate=1e-4), metrics = ['accuracy'])

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   )
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150,150),
    batch_size=25,
    class_mode = 'binary'
)

validation_generator = test_datagen.flow_from_directory(
    validation_dir,
    target_size=(150,150),
    batch_size=25,
    class_mode = 'binary'
)

history = model.fit_generator(
    train_generator,
    steps_per_epoch=20,
    epochs=30,
    validation_data = validation_generator,
    validation_steps=10
)

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, 'bo', label='Training Accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.legend()

plt.show()

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150,150),
    batch_size=25,
    class_mode = 'binary'
)

model.evaluate(test_generator)

model.save('/content/gdrive/MyDrive/한이음자율형/Front_and_Top_2021_07_04.h5')